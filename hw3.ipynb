{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chris-STAT/cs_dl/blob/main/hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYofdo-HRYcZ",
        "outputId": "2ebbe58a-ab8c-4dac-a290-a8aad9558ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'utdl'...\n",
            "remote: Enumerating objects: 45344, done.\u001b[K\n",
            "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 45344 (delta 108), reused 99 (delta 59), pack-reused 45195 (from 1)\u001b[K\n",
            "Receiving objects: 100% (45344/45344), 133.28 MiB | 64.20 MiB/s, done.\n",
            "Resolving deltas: 100% (1822/1822), done.\n",
            "Updating files: 100% (75086/75086), done.\n",
            "/content/utdl/homework3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ['USER'] = 'Chris-STAT'\n",
        "os.environ['PASS'] = 'baiou2350296'\n",
        "os.environ['REPO'] = 'utdl'\n",
        "\n",
        "!git clone https://$USER:$PASS@github.com/$USER/$REPO.git\n",
        "\n",
        "%cd utdl/homework3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt1zbVFkSAvi",
        "outputId": "7a8614ac-8f58-45a1-f62a-d214ecb3867b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItpP16FWSIG6",
        "outputId": "ec5f02ee-7367-4c65-99ce-66348e7905f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: Pillow>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (10.4.0)\n",
            "Requirement already satisfied: tensorboard>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.17.0)\n",
            "Collecting termcolor==2.4.0 (from -r requirements.txt (line 4))\n",
            "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opencv-python>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.0.0->-r requirements.txt (line 3)) (3.0.2)\n",
            "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: termcolor\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.5.0\n",
            "    Uninstalling termcolor-2.5.0:\n",
            "      Successfully uninstalled termcolor-2.5.0\n",
            "Successfully installed termcolor-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNxIP9ZzHa6Q",
        "outputId": "b669190c-92eb-4e9e-ec83-de01128c92c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-04 04:59:38.253794: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-04 04:59:38.271959: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-04 04:59:38.293974: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-04 04:59:38.300520: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-04 04:59:38.316578: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-04 04:59:39.413497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch  1 / 50: train_acc=0.5338 val_acc=0.5506\n",
            "Epoch 10 / 50: train_acc=0.9213 val_acc=0.7059\n",
            "Epoch 20 / 50: train_acc=0.9587 val_acc=0.7645\n",
            "Epoch 30 / 50: train_acc=0.9705 val_acc=0.8124\n",
            "Epoch 40 / 50: train_acc=0.9774 val_acc=0.8407\n",
            "Epoch 50 / 50: train_acc=0.9819 val_acc=0.8811\n",
            "Model saved to logs/classifier_1104_045942/classifier.th\n"
          ]
        }
      ],
      "source": [
        "!python3 -m homework.train_classification --model_name classifier --batch_size=64 --lr=3e-4 --num_epoch=50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8dgSGBnhYsL",
        "outputId": "5f0c0953-64af-485b-efa7-d12a3d7acc94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-04 15:25:36.192281: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-04 15:25:36.209884: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-04 15:25:36.230946: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-04 15:25:36.237456: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-04 15:25:36.253582: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-04 15:25:37.383396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch  1 / 150: train_acc=0.4965 val_acc=0.6535train_mse=0.7342 val_mse=0.5718\n",
            "Epoch 10 / 150: train_acc=0.9546 val_acc=0.9556train_mse=0.0551 val_mse=0.0537\n",
            "Epoch 20 / 150: train_acc=0.9492 val_acc=0.9476train_mse=0.0382 val_mse=0.0378\n",
            "Epoch 30 / 150: train_acc=0.9257 val_acc=0.9248train_mse=0.0308 val_mse=0.0304\n",
            "Epoch 40 / 150: train_acc=0.9188 val_acc=0.9112train_mse=0.0270 val_mse=0.0273\n",
            "Epoch 50 / 150: train_acc=0.9123 val_acc=0.9057train_mse=0.0245 val_mse=0.0249\n",
            "Epoch 60 / 150: train_acc=0.9045 val_acc=0.9032train_mse=0.0233 val_mse=0.0230\n",
            "Epoch 70 / 150: train_acc=0.9086 val_acc=0.9049train_mse=0.0220 val_mse=0.0224\n",
            "Epoch 80 / 150: train_acc=0.9158 val_acc=0.9166train_mse=0.0197 val_mse=0.0195\n",
            "Epoch 90 / 150: train_acc=0.9207 val_acc=0.9172train_mse=0.0178 val_mse=0.0176\n",
            "Epoch 100 / 150: train_acc=0.9241 val_acc=0.9258train_mse=0.0165 val_mse=0.0163\n",
            "Epoch 110 / 150: train_acc=0.9283 val_acc=0.9318train_mse=0.0155 val_mse=0.0152\n",
            "Epoch 120 / 150: train_acc=0.9308 val_acc=0.9255train_mse=0.0149 val_mse=0.0149\n",
            "Epoch 130 / 150: train_acc=0.9325 val_acc=0.9297train_mse=0.0143 val_mse=0.0142\n",
            "Epoch 140 / 150: train_acc=0.9340 val_acc=0.9316train_mse=0.0138 val_mse=0.0137\n",
            "Epoch 150 / 150: train_acc=0.9360 val_acc=0.9368train_mse=0.0134 val_mse=0.0134\n",
            "Model saved to logs/detector_1104_152540/detector.th\n"
          ]
        }
      ],
      "source": [
        "!python3 -m homework.train_detection --model_name detector --batch_size=128 --lr=5e-4 --num_epoch=150 --class_wgt=\"0.04,0.48,0.48\" --loss_wgt=0.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m homework.train_detection --model_name detector --batch_size=128 --lr=5e-4 --num_epoch=150 --class_wgt=\"0.04,0.48,0.48\" --loss_wgt=0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzyrmw9o4AZo",
        "outputId": "8c268bae-bf56-4449-9392-f592845cbdbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-04 15:55:24.496040: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-04 15:55:24.513657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-04 15:55:24.534966: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-04 15:55:24.541292: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-04 15:55:24.556565: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-04 15:55:25.667523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch  1 / 150: train_acc=0.4835 val_acc=0.5855train_mse=0.6130 val_mse=0.3694\n",
            "Epoch 10 / 150: train_acc=0.9256 val_acc=0.9317train_mse=0.0358 val_mse=0.0347\n",
            "Epoch 20 / 150: train_acc=0.9567 val_acc=0.9567train_mse=0.0247 val_mse=0.0242\n",
            "Epoch 30 / 150: train_acc=0.9541 val_acc=0.9536train_mse=0.0208 val_mse=0.0205\n",
            "Epoch 40 / 150: train_acc=0.9378 val_acc=0.9373train_mse=0.0185 val_mse=0.0184\n",
            "Epoch 50 / 150: train_acc=0.9276 val_acc=0.9281train_mse=0.0171 val_mse=0.0168\n",
            "Epoch 60 / 150: train_acc=0.9228 val_acc=0.9215train_mse=0.0162 val_mse=0.0161\n",
            "Epoch 70 / 150: train_acc=0.9177 val_acc=0.9155train_mse=0.0155 val_mse=0.0153\n",
            "Epoch 80 / 150: train_acc=0.9165 val_acc=0.9216train_mse=0.0151 val_mse=0.0148\n",
            "Epoch 90 / 150: train_acc=0.9145 val_acc=0.9204train_mse=0.0144 val_mse=0.0141\n",
            "Epoch 100 / 150: train_acc=0.9051 val_acc=0.9148train_mse=0.0146 val_mse=0.0142\n",
            "Epoch 110 / 150: train_acc=0.9074 val_acc=0.9073train_mse=0.0143 val_mse=0.0142\n",
            "Epoch 120 / 150: train_acc=0.9146 val_acc=0.9129train_mse=0.0133 val_mse=0.0132\n",
            "Epoch 130 / 150: train_acc=0.9192 val_acc=0.9111train_mse=0.0125 val_mse=0.0125\n",
            "Epoch 140 / 150: train_acc=0.9225 val_acc=0.9197train_mse=0.0120 val_mse=0.0119\n",
            "Epoch 150 / 150: train_acc=0.9246 val_acc=0.9270train_mse=0.0116 val_mse=0.0115\n",
            "Model saved to logs/detector_1104_155528/detector.th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m homework.train_detection --model_name detector --batch_size=128 --lr=5e-4 --num_epoch=500 --class_wgt=\"0.06,0.47,0.47\" --loss_wgt=0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ldz5I-Y_pue",
        "outputId": "9f896c71-4e66-46f7-a773-9ab9fdbf727c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-04 17:24:53.169446: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-04 17:24:53.187167: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-04 17:24:53.208304: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-04 17:24:53.214714: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-04 17:24:53.230098: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-04 17:24:54.335012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch  1 / 500: train_acc=0.4903 val_acc=0.6014train_mse=0.6124 val_mse=0.3672\n",
            "Epoch 10 / 500: train_acc=0.9518 val_acc=0.9538train_mse=0.0354 val_mse=0.0343\n",
            "Epoch 20 / 500: train_acc=0.9591 val_acc=0.9591train_mse=0.0244 val_mse=0.0240\n",
            "Epoch 30 / 500: train_acc=0.9591 val_acc=0.9591train_mse=0.0210 val_mse=0.0206\n",
            "Epoch 40 / 500: train_acc=0.9591 val_acc=0.9591train_mse=0.0187 val_mse=0.0185\n",
            "Epoch 50 / 500: train_acc=0.9591 val_acc=0.9591train_mse=0.0170 val_mse=0.0168\n",
            "Epoch 60 / 500: train_acc=0.9589 val_acc=0.9588train_mse=0.0158 val_mse=0.0156\n",
            "Epoch 70 / 500: train_acc=0.9517 val_acc=0.9508train_mse=0.0151 val_mse=0.0149\n",
            "Epoch 80 / 500: train_acc=0.9412 val_acc=0.9418train_mse=0.0147 val_mse=0.0144\n",
            "Epoch 90 / 500: train_acc=0.9336 val_acc=0.9309train_mse=0.0145 val_mse=0.0144\n",
            "Epoch 100 / 500: train_acc=0.9327 val_acc=0.9313train_mse=0.0139 val_mse=0.0137\n",
            "Epoch 110 / 500: train_acc=0.9345 val_acc=0.9342train_mse=0.0130 val_mse=0.0129\n",
            "Epoch 120 / 500: train_acc=0.9349 val_acc=0.9362train_mse=0.0124 val_mse=0.0123\n",
            "Epoch 130 / 500: train_acc=0.9323 val_acc=0.9306train_mse=0.0121 val_mse=0.0121\n",
            "Epoch 140 / 500: train_acc=0.9297 val_acc=0.9329train_mse=0.0122 val_mse=0.0120\n",
            "Epoch 150 / 500: train_acc=0.9271 val_acc=0.9264train_mse=0.0123 val_mse=0.0123\n",
            "Epoch 160 / 500: train_acc=0.9290 val_acc=0.9288train_mse=0.0123 val_mse=0.0122\n",
            "Epoch 170 / 500: train_acc=0.9329 val_acc=0.9343train_mse=0.0119 val_mse=0.0118\n",
            "Epoch 180 / 500: train_acc=0.9359 val_acc=0.9354train_mse=0.0115 val_mse=0.0114\n",
            "Epoch 190 / 500: train_acc=0.9376 val_acc=0.9375train_mse=0.0112 val_mse=0.0111\n",
            "Epoch 200 / 500: train_acc=0.9393 val_acc=0.9392train_mse=0.0109 val_mse=0.0107\n",
            "Epoch 210 / 500: train_acc=0.9407 val_acc=0.9403train_mse=0.0106 val_mse=0.0105\n",
            "Epoch 220 / 500: train_acc=0.9417 val_acc=0.9408train_mse=0.0103 val_mse=0.0103\n",
            "Epoch 230 / 500: train_acc=0.9422 val_acc=0.9422train_mse=0.0102 val_mse=0.0101\n",
            "Epoch 240 / 500: train_acc=0.9436 val_acc=0.9435train_mse=0.0100 val_mse=0.0098\n",
            "Epoch 250 / 500: train_acc=0.9442 val_acc=0.9430train_mse=0.0098 val_mse=0.0096\n",
            "Epoch 260 / 500: train_acc=0.9448 val_acc=0.9433train_mse=0.0097 val_mse=0.0096\n",
            "Epoch 270 / 500: train_acc=0.9456 val_acc=0.9450train_mse=0.0095 val_mse=0.0094\n",
            "Epoch 280 / 500: train_acc=0.9462 val_acc=0.9471train_mse=0.0094 val_mse=0.0093\n",
            "Epoch 290 / 500: train_acc=0.9468 val_acc=0.9461train_mse=0.0093 val_mse=0.0092\n",
            "Epoch 300 / 500: train_acc=0.9472 val_acc=0.9471train_mse=0.0092 val_mse=0.0091\n",
            "Epoch 310 / 500: train_acc=0.9481 val_acc=0.9467train_mse=0.0091 val_mse=0.0090\n",
            "Epoch 320 / 500: train_acc=0.9484 val_acc=0.9476train_mse=0.0090 val_mse=0.0089\n",
            "Epoch 330 / 500: train_acc=0.9490 val_acc=0.9490train_mse=0.0089 val_mse=0.0088\n",
            "Epoch 340 / 500: train_acc=0.9497 val_acc=0.9513train_mse=0.0088 val_mse=0.0086\n",
            "Epoch 350 / 500: train_acc=0.9502 val_acc=0.9502train_mse=0.0087 val_mse=0.0086\n",
            "Epoch 360 / 500: train_acc=0.9509 val_acc=0.9511train_mse=0.0086 val_mse=0.0085\n",
            "Epoch 370 / 500: train_acc=0.9512 val_acc=0.9516train_mse=0.0085 val_mse=0.0084\n",
            "Epoch 380 / 500: train_acc=0.9518 val_acc=0.9527train_mse=0.0084 val_mse=0.0082\n",
            "Epoch 390 / 500: train_acc=0.9522 val_acc=0.9511train_mse=0.0083 val_mse=0.0082\n",
            "Epoch 400 / 500: train_acc=0.9526 val_acc=0.9525train_mse=0.0082 val_mse=0.0081\n",
            "Epoch 410 / 500: train_acc=0.9532 val_acc=0.9526train_mse=0.0081 val_mse=0.0080\n",
            "Epoch 420 / 500: train_acc=0.9537 val_acc=0.9549train_mse=0.0080 val_mse=0.0079\n",
            "Epoch 430 / 500: train_acc=0.9542 val_acc=0.9555train_mse=0.0079 val_mse=0.0078\n",
            "Epoch 440 / 500: train_acc=0.9548 val_acc=0.9542train_mse=0.0078 val_mse=0.0077\n",
            "Epoch 450 / 500: train_acc=0.9552 val_acc=0.9540train_mse=0.0077 val_mse=0.0077\n",
            "Epoch 460 / 500: train_acc=0.9555 val_acc=0.9575train_mse=0.0076 val_mse=0.0075\n",
            "Epoch 470 / 500: train_acc=0.9558 val_acc=0.9564train_mse=0.0076 val_mse=0.0075\n",
            "Epoch 480 / 500: train_acc=0.9566 val_acc=0.9553train_mse=0.0075 val_mse=0.0074\n",
            "Epoch 490 / 500: train_acc=0.9572 val_acc=0.9574train_mse=0.0074 val_mse=0.0073\n",
            "Epoch 500 / 500: train_acc=0.9570 val_acc=0.9561train_mse=0.0073 val_mse=0.0072\n",
            "Model saved to logs/detector_1104_172457/detector.th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m homework.train_detection --model_name detector --batch_size=128 --lr=5e-4 --num_epoch=500 --class_wgt=\"0.04,0.48,0.48\" --loss_wgt=0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpan0_9hjn8C",
        "outputId": "7741c409-1545-4bbc-945b-6f279d4f75be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-04 19:04:32.347735: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-04 19:04:32.365619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-04 19:04:32.387578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-04 19:04:32.394040: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-04 19:04:32.409862: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-04 19:04:33.525291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch  1 / 500: train_acc=0.4835 val_acc=0.5855train_mse=0.6130 val_mse=0.3694\n",
            "Epoch 10 / 500: train_acc=0.9256 val_acc=0.9317train_mse=0.0358 val_mse=0.0347\n",
            "Epoch 20 / 500: train_acc=0.9567 val_acc=0.9567train_mse=0.0247 val_mse=0.0242\n",
            "Epoch 30 / 500: train_acc=0.9541 val_acc=0.9536train_mse=0.0208 val_mse=0.0205\n",
            "Epoch 40 / 500: train_acc=0.9378 val_acc=0.9374train_mse=0.0185 val_mse=0.0184\n",
            "Epoch 50 / 500: train_acc=0.9276 val_acc=0.9281train_mse=0.0171 val_mse=0.0168\n",
            "Epoch 60 / 500: train_acc=0.9228 val_acc=0.9216train_mse=0.0162 val_mse=0.0161\n",
            "Epoch 70 / 500: train_acc=0.9177 val_acc=0.9154train_mse=0.0155 val_mse=0.0153\n",
            "Epoch 80 / 500: train_acc=0.9165 val_acc=0.9215train_mse=0.0151 val_mse=0.0148\n",
            "Epoch 90 / 500: train_acc=0.9145 val_acc=0.9203train_mse=0.0144 val_mse=0.0141\n",
            "Epoch 100 / 500: train_acc=0.9051 val_acc=0.9148train_mse=0.0146 val_mse=0.0142\n",
            "Epoch 110 / 500: train_acc=0.9074 val_acc=0.9074train_mse=0.0143 val_mse=0.0142\n",
            "Epoch 120 / 500: train_acc=0.9146 val_acc=0.9131train_mse=0.0133 val_mse=0.0132\n",
            "Epoch 130 / 500: train_acc=0.9192 val_acc=0.9110train_mse=0.0125 val_mse=0.0125\n",
            "Epoch 140 / 500: train_acc=0.9225 val_acc=0.9198train_mse=0.0120 val_mse=0.0119\n",
            "Epoch 150 / 500: train_acc=0.9246 val_acc=0.9270train_mse=0.0116 val_mse=0.0115\n",
            "Epoch 160 / 500: train_acc=0.9266 val_acc=0.9286train_mse=0.0113 val_mse=0.0111\n",
            "Epoch 170 / 500: train_acc=0.9283 val_acc=0.9305train_mse=0.0110 val_mse=0.0109\n",
            "Epoch 180 / 500: train_acc=0.9295 val_acc=0.9304train_mse=0.0108 val_mse=0.0106\n",
            "Epoch 190 / 500: train_acc=0.9305 val_acc=0.9319train_mse=0.0106 val_mse=0.0104\n",
            "Epoch 200 / 500: train_acc=0.9317 val_acc=0.9310train_mse=0.0104 val_mse=0.0102\n",
            "Epoch 210 / 500: train_acc=0.9330 val_acc=0.9360train_mse=0.0102 val_mse=0.0100\n",
            "Epoch 220 / 500: train_acc=0.9340 val_acc=0.9306train_mse=0.0100 val_mse=0.0100\n",
            "Epoch 230 / 500: train_acc=0.9346 val_acc=0.9354train_mse=0.0099 val_mse=0.0098\n",
            "Epoch 240 / 500: train_acc=0.9356 val_acc=0.9379train_mse=0.0098 val_mse=0.0096\n",
            "Epoch 250 / 500: train_acc=0.9362 val_acc=0.9292train_mse=0.0097 val_mse=0.0095\n",
            "Epoch 260 / 500: train_acc=0.9373 val_acc=0.9338train_mse=0.0095 val_mse=0.0094\n",
            "Epoch 270 / 500: train_acc=0.9383 val_acc=0.9362train_mse=0.0094 val_mse=0.0093\n",
            "Epoch 280 / 500: train_acc=0.9387 val_acc=0.9355train_mse=0.0093 val_mse=0.0092\n",
            "Epoch 290 / 500: train_acc=0.9399 val_acc=0.9370train_mse=0.0092 val_mse=0.0091\n",
            "Epoch 300 / 500: train_acc=0.9403 val_acc=0.9407train_mse=0.0091 val_mse=0.0090\n",
            "Epoch 310 / 500: train_acc=0.9412 val_acc=0.9391train_mse=0.0090 val_mse=0.0089\n",
            "Epoch 320 / 500: train_acc=0.9419 val_acc=0.9405train_mse=0.0089 val_mse=0.0088\n",
            "Epoch 330 / 500: train_acc=0.9428 val_acc=0.9412train_mse=0.0088 val_mse=0.0088\n",
            "Epoch 340 / 500: train_acc=0.9435 val_acc=0.9452train_mse=0.0088 val_mse=0.0086\n",
            "Epoch 350 / 500: train_acc=0.9440 val_acc=0.9452train_mse=0.0087 val_mse=0.0086\n",
            "Epoch 360 / 500: train_acc=0.9449 val_acc=0.9468train_mse=0.0086 val_mse=0.0085\n",
            "Epoch 370 / 500: train_acc=0.9451 val_acc=0.9459train_mse=0.0086 val_mse=0.0084\n",
            "Epoch 380 / 500: train_acc=0.9461 val_acc=0.9484train_mse=0.0085 val_mse=0.0083\n",
            "Epoch 390 / 500: train_acc=0.9465 val_acc=0.9450train_mse=0.0084 val_mse=0.0083\n",
            "Epoch 400 / 500: train_acc=0.9470 val_acc=0.9468train_mse=0.0083 val_mse=0.0082\n",
            "Epoch 410 / 500: train_acc=0.9476 val_acc=0.9462train_mse=0.0083 val_mse=0.0081\n",
            "Epoch 420 / 500: train_acc=0.9484 val_acc=0.9515train_mse=0.0081 val_mse=0.0080\n",
            "Epoch 430 / 500: train_acc=0.9491 val_acc=0.9531train_mse=0.0081 val_mse=0.0080\n",
            "Epoch 440 / 500: train_acc=0.9498 val_acc=0.9511train_mse=0.0081 val_mse=0.0079\n",
            "Epoch 450 / 500: train_acc=0.9503 val_acc=0.9487train_mse=0.0079 val_mse=0.0078\n",
            "Epoch 460 / 500: train_acc=0.9507 val_acc=0.9508train_mse=0.0078 val_mse=0.0077\n",
            "Epoch 470 / 500: train_acc=0.9510 val_acc=0.9514train_mse=0.0078 val_mse=0.0077\n",
            "Epoch 480 / 500: train_acc=0.9519 val_acc=0.9510train_mse=0.0077 val_mse=0.0076\n",
            "Epoch 490 / 500: train_acc=0.9525 val_acc=0.9499train_mse=0.0076 val_mse=0.0075\n",
            "Epoch 500 / 500: train_acc=0.9529 val_acc=0.9527train_mse=0.0076 val_mse=0.0074\n",
            "Model saved to logs/detector_1104_190436/detector.th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m homework.train_detection --model_name detector --batch_size=128 --lr=3e-4 --num_epoch=2000 --class_wgt=\"0.06,0.47,0.47\" --loss_wgt=0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvcDFxHBz6P6",
        "outputId": "44059fd7-af84-4aaf-b42f-7c6b6e31f0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-04 22:47:50.864647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-04 22:47:50.884592: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-04 22:47:50.889696: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-04 22:47:50.903390: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-04 22:47:52.155002: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "CUDA not available, using CPU\n",
            "Epoch  1 / 2000: train_acc=0.4881 val_acc=0.5928train_mse=0.7069 val_mse=0.5195\n",
            "Epoch 10 / 2000: train_acc=0.8906 val_acc=0.9014train_mse=0.0479 val_mse=0.0465\n",
            "Epoch 20 / 2000: train_acc=0.9574 val_acc=0.9576train_mse=0.0314 val_mse=0.0308\n",
            "Epoch 30 / 2000: train_acc=0.9591 val_acc=0.9591train_mse=0.0256 val_mse=0.0251\n",
            "Epoch 40 / 2000: train_acc=0.9591 val_acc=0.9591train_mse=0.0227 val_mse=0.0225\n",
            "Epoch 50 / 2000: train_acc=0.9591 val_acc=0.9591train_mse=0.0210 val_mse=0.0207\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/utdl/homework3/homework/train_detection.py\", line 159, in <module>\n",
            "    train(**vars(args))\n",
            "  File \"/content/utdl/homework3/homework/train_detection.py\", line 83, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 581, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "J2biOn_j_tBE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiWoEMQfiMVs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m grader homework -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rgxy0ViO-NQ-",
        "outputId": "542589af-143c-4eee-ab46-2b4a09388854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public grader loaded.\n",
            "\u001b[97m[INFO     00:00:002] \u001b[0m\u001b[97mClassifier\u001b[0m\n",
            "\u001b[97m[INFO     00:00:567] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "/content/utdl/homework3/./homework/models.py:670: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  m.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
            "\u001b[97m[INFO     00:04:423] \u001b[0m\u001b[97m  - Accuracy                                           [ 25 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:04:423] \u001b[0m\u001b[33maccuracy: 0.881\u001b[0m\n",
            "\u001b[97m[INFO     00:04:423] \u001b[0m\u001b[97m  - Accuracy: Extra Credit                             [ 2 / 2 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:427] \u001b[0m\u001b[97m --------------------------------------------------    [  37 /  35 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:430] \u001b[0m\u001b[97mDetector\u001b[0m\n",
            "\u001b[97m[INFO     00:04:758] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:729] \u001b[0m\u001b[33m  - Segmentation Accuracy                              [ 0 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:730] \u001b[0m\u001b[33maccuracy: 0.949\u001b[0m\n",
            "\u001b[97m[INFO     00:07:730] \u001b[0m\u001b[97m  - Segmentation IoU                                   [ 25 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:730] \u001b[0m\u001b[33miou: 0.600\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:730] \u001b[0m\u001b[33m  - Segmentation IoU: Extra Credit                     [ 0 / 2 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:730] \u001b[0m\u001b[33m  - Depth Error                                        [ 7 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:731] \u001b[0m\u001b[33mabs_depth_error: 0.060\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:731] \u001b[0m\u001b[33m  - Depth Error: Extra Credit                          [ 0 / 2 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:731] \u001b[0m\u001b[33m  - True Positives Depth Error                         [ 8 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:731] \u001b[0m\u001b[33mtp_depth_error: 0.058\u001b[0m\n",
            "\u001b[97m[INFO     00:07:732] \u001b[0m\u001b[97m --------------------------------------------------    [  50 /  65 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:07:732] \u001b[0m\u001b[97mTotal                                                     87 / 100\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m grader homework -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft46rYgNuZGv",
        "outputId": "97a4ef1f-09c4-49f6-fcea-585c1c5f018e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public grader loaded.\n",
            "\u001b[97m[INFO     00:00:002] \u001b[0m\u001b[97mClassifier\u001b[0m\n",
            "\u001b[97m[INFO     00:00:557] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "/content/utdl/homework3/./homework/models.py:670: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  m.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
            "\u001b[97m[INFO     00:04:367] \u001b[0m\u001b[97m  - Accuracy                                           [ 25 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:04:367] \u001b[0m\u001b[33maccuracy: 0.881\u001b[0m\n",
            "\u001b[97m[INFO     00:04:368] \u001b[0m\u001b[97m  - Accuracy: Extra Credit                             [ 2 / 2 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:371] \u001b[0m\u001b[97m --------------------------------------------------    [  37 /  35 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:374] \u001b[0m\u001b[97mDetector\u001b[0m\n",
            "\u001b[97m[INFO     00:04:690] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:671] \u001b[0m\u001b[33m  - Segmentation Accuracy                              [ 3 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:671] \u001b[0m\u001b[33maccuracy: 0.953\u001b[0m\n",
            "\u001b[97m[INFO     00:07:671] \u001b[0m\u001b[97m  - Segmentation IoU                                   [ 25 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:671] \u001b[0m\u001b[33miou: 0.609\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:671] \u001b[0m\u001b[33m  - Segmentation IoU: Extra Credit                     [ 1 / 2 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:672] \u001b[0m\u001b[33m  - Depth Error                                        [ 7 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:672] \u001b[0m\u001b[33mabs_depth_error: 0.059\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:672] \u001b[0m\u001b[33m  - Depth Error: Extra Credit                          [ 0 / 2 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:672] \u001b[0m\u001b[33m  - True Positives Depth Error                         [ 8 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:672] \u001b[0m\u001b[33mtp_depth_error: 0.057\u001b[0m\n",
            "\u001b[97m[INFO     00:07:673] \u001b[0m\u001b[97m --------------------------------------------------    [  54 /  65 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:07:673] \u001b[0m\u001b[97mTotal                                                     91 / 100\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRsAalyqVoLe",
        "outputId": "ecf5cb3d-f989-4053-90a8-a5bc76f1c2c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public grader loaded.\n",
            "\u001b[97m[INFO     00:00:002] \u001b[0m\u001b[97mClassifier\u001b[0m\n",
            "\u001b[97m[INFO     00:00:606] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "/content/utdl/homework3/./homework/models.py:670: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  m.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
            "\u001b[97m[INFO     00:04:478] \u001b[0m\u001b[97m  - Accuracy                                           [ 25 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:04:479] \u001b[0m\u001b[33maccuracy: 0.881\u001b[0m\n",
            "\u001b[97m[INFO     00:04:479] \u001b[0m\u001b[97m  - Accuracy: Extra Credit                             [ 2 / 2 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:483] \u001b[0m\u001b[97m --------------------------------------------------    [  37 /  35 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:485] \u001b[0m\u001b[97mDetector\u001b[0m\n",
            "\u001b[97m[INFO     00:04:858] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:921] \u001b[0m\u001b[33m  - Segmentation Accuracy                              [ 0 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:922] \u001b[0m\u001b[33maccuracy: 0.934\u001b[0m\n",
            "\u001b[97m[INFO     00:07:922] \u001b[0m\u001b[97m  - Segmentation IoU                                   [ 25 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:922] \u001b[0m\u001b[33miou: 0.549\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:922] \u001b[0m\u001b[33m  - Segmentation IoU: Extra Credit                     [ 0 / 2 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:922] \u001b[0m\u001b[33m  - Depth Error                                        [ 0 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:922] \u001b[0m\u001b[33mabs_depth_error: 0.081\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:923] \u001b[0m\u001b[33m  - Depth Error: Extra Credit                          [ 0 / 2 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:923] \u001b[0m\u001b[33m  - True Positives Depth Error                         [ 4 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:07:923] \u001b[0m\u001b[33mtp_depth_error: 0.074\u001b[0m\n",
            "\u001b[97m[INFO     00:07:924] \u001b[0m\u001b[97m --------------------------------------------------    [  39 /  65 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:07:924] \u001b[0m\u001b[97mTotal                                                     76 / 100\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m grader homework -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm4--GC5uo4z",
        "outputId": "638b3208-a64e-462d-d9f5-a1bb2b355292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/utdl/homework3\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEeDMQZSud28"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.tensorboard as tb\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from homework.models import ClassificationLoss, RegressionLoss, Detector, load_model, save_model\n",
        "from homework.datasets.road_dataset import load_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTAfXlRZu8Be"
      },
      "outputs": [],
      "source": [
        "train_data = load_data(\"road_data/train\", batch_size=128, shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "XfqTIlG9vK1H",
        "outputId": "a886ca58-d83a-4c9b-cd3f-5238ce400b3b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-270481b8c6ef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"track\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "for batch in train_data:\n",
        "            img = batch[\"image\"].to(device)\n",
        "            depth = batch[\"depth\"].to(device)\n",
        "            track = batch[\"track\"].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuWZTLvgw1q3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRtjJmJpw2Pd",
        "outputId": "44b37b87-ef93-4325-9a08-ec07a875605d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'image': tensor([[[[0.3137, 0.3137, 0.3098,  ..., 0.3020, 0.3020, 0.3020],\n",
              "           [0.3176, 0.3137, 0.3137,  ..., 0.3098, 0.3098, 0.3059],\n",
              "           [0.3255, 0.3255, 0.3255,  ..., 0.3137, 0.3098, 0.3098],\n",
              "           ...,\n",
              "           [0.4824, 0.4784, 0.4706,  ..., 0.3373, 0.3490, 0.3686],\n",
              "           [0.4784, 0.4745, 0.4706,  ..., 0.3333, 0.3294, 0.3333],\n",
              "           [0.4627, 0.4588, 0.4549,  ..., 0.3373, 0.3216, 0.3098]],\n",
              " \n",
              "          [[0.3647, 0.3647, 0.3608,  ..., 0.3451, 0.3451, 0.3451],\n",
              "           [0.3686, 0.3647, 0.3647,  ..., 0.3529, 0.3529, 0.3490],\n",
              "           [0.3686, 0.3686, 0.3686,  ..., 0.3569, 0.3529, 0.3529],\n",
              "           ...,\n",
              "           [0.2784, 0.2745, 0.2667,  ..., 0.3647, 0.3843, 0.4039],\n",
              "           [0.2745, 0.2706, 0.2667,  ..., 0.3765, 0.3843, 0.3882],\n",
              "           [0.2588, 0.2549, 0.2510,  ..., 0.3922, 0.3804, 0.3686]],\n",
              " \n",
              "          [[0.4392, 0.4392, 0.4353,  ..., 0.4235, 0.4235, 0.4235],\n",
              "           [0.4431, 0.4392, 0.4392,  ..., 0.4314, 0.4314, 0.4275],\n",
              "           [0.4392, 0.4392, 0.4392,  ..., 0.4275, 0.4235, 0.4235],\n",
              "           ...,\n",
              "           [0.0824, 0.0784, 0.0706,  ..., 0.2353, 0.2627, 0.2824],\n",
              "           [0.0784, 0.0745, 0.0706,  ..., 0.2431, 0.2549, 0.2588],\n",
              "           [0.0627, 0.0588, 0.0549,  ..., 0.2549, 0.2510, 0.2392]]],\n",
              " \n",
              " \n",
              "         [[[0.0196, 0.0235, 0.0235,  ..., 0.8745, 0.8549, 0.8275],\n",
              "           [0.0235, 0.0235, 0.0275,  ..., 0.8549, 0.8588, 0.8863],\n",
              "           [0.0275, 0.0314, 0.0314,  ..., 0.8510, 0.8314, 0.8157],\n",
              "           ...,\n",
              "           [0.7922, 0.7490, 0.6863,  ..., 0.6471, 0.6627, 0.6588],\n",
              "           [0.7412, 0.6980, 0.6471,  ..., 0.6706, 0.6588, 0.6627],\n",
              "           [0.6549, 0.6353, 0.6314,  ..., 0.6275, 0.6431, 0.6824]],\n",
              " \n",
              "          [[0.0353, 0.0392, 0.0392,  ..., 0.8627, 0.8510, 0.8235],\n",
              "           [0.0392, 0.0392, 0.0431,  ..., 0.8431, 0.8549, 0.8824],\n",
              "           [0.0431, 0.0471, 0.0471,  ..., 0.8471, 0.8275, 0.8118],\n",
              "           ...,\n",
              "           [0.7882, 0.7451, 0.6824,  ..., 0.6471, 0.6627, 0.6588],\n",
              "           [0.7373, 0.6941, 0.6431,  ..., 0.6706, 0.6588, 0.6627],\n",
              "           [0.6510, 0.6314, 0.6275,  ..., 0.6275, 0.6431, 0.6824]],\n",
              " \n",
              "          [[0.0824, 0.0863, 0.0863,  ..., 0.8902, 0.8745, 0.8471],\n",
              "           [0.0863, 0.0863, 0.0902,  ..., 0.8706, 0.8784, 0.9059],\n",
              "           [0.0902, 0.0941, 0.0941,  ..., 0.8706, 0.8510, 0.8353],\n",
              "           ...,\n",
              "           [0.8118, 0.7686, 0.7059,  ..., 0.6549, 0.6706, 0.6667],\n",
              "           [0.7608, 0.7176, 0.6667,  ..., 0.6784, 0.6667, 0.6706],\n",
              "           [0.6745, 0.6549, 0.6510,  ..., 0.6353, 0.6510, 0.6902]]],\n",
              " \n",
              " \n",
              "         [[[0.2510, 0.2510, 0.2549,  ..., 0.2275, 0.2314, 0.2353],\n",
              "           [0.2549, 0.2549, 0.2549,  ..., 0.2235, 0.2275, 0.2275],\n",
              "           [0.2627, 0.2627, 0.2588,  ..., 0.2275, 0.2275, 0.2275],\n",
              "           ...,\n",
              "           [0.5765, 0.5725, 0.5647,  ..., 0.4196, 0.4235, 0.4314],\n",
              "           [0.5686, 0.5569, 0.5451,  ..., 0.4078, 0.4078, 0.4078],\n",
              "           [0.5569, 0.5412, 0.5216,  ..., 0.4392, 0.4235, 0.4118]],\n",
              " \n",
              "          [[0.2902, 0.2902, 0.2941,  ..., 0.2980, 0.3020, 0.3059],\n",
              "           [0.2980, 0.2980, 0.2980,  ..., 0.2941, 0.2980, 0.2980],\n",
              "           [0.3137, 0.3137, 0.3098,  ..., 0.2902, 0.2902, 0.2902],\n",
              "           ...,\n",
              "           [0.3647, 0.3608, 0.3529,  ..., 0.4196, 0.4235, 0.4314],\n",
              "           [0.3569, 0.3451, 0.3333,  ..., 0.4078, 0.4000, 0.4000],\n",
              "           [0.3451, 0.3294, 0.3098,  ..., 0.4392, 0.4157, 0.4039]],\n",
              " \n",
              "          [[0.3961, 0.3961, 0.3922,  ..., 0.3843, 0.3961, 0.4000],\n",
              "           [0.3765, 0.3765, 0.3765,  ..., 0.3804, 0.3922, 0.3922],\n",
              "           [0.3451, 0.3451, 0.3412,  ..., 0.3882, 0.3882, 0.3882],\n",
              "           ...,\n",
              "           [0.0824, 0.0784, 0.0706,  ..., 0.3176, 0.3216, 0.3294],\n",
              "           [0.0745, 0.0627, 0.0510,  ..., 0.3059, 0.3020, 0.3020],\n",
              "           [0.0627, 0.0471, 0.0275,  ..., 0.3373, 0.3176, 0.3059]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[0.7333, 0.7333, 0.7294,  ..., 0.5882, 0.5569, 0.5176],\n",
              "           [0.7333, 0.7333, 0.7333,  ..., 0.5725, 0.5451, 0.5137],\n",
              "           [0.7373, 0.7373, 0.7373,  ..., 0.5569, 0.5333, 0.5098],\n",
              "           ...,\n",
              "           [0.5804, 0.5725, 0.5569,  ..., 0.5843, 0.5804, 0.5569],\n",
              "           [0.5765, 0.5647, 0.5451,  ..., 0.6039, 0.6039, 0.5804],\n",
              "           [0.5686, 0.5569, 0.5412,  ..., 0.6039, 0.5961, 0.5647]],\n",
              " \n",
              "          [[0.4941, 0.4941, 0.4902,  ..., 0.7176, 0.7294, 0.7059],\n",
              "           [0.4941, 0.4941, 0.4941,  ..., 0.7020, 0.7176, 0.7020],\n",
              "           [0.4980, 0.4980, 0.4980,  ..., 0.6863, 0.7059, 0.6980],\n",
              "           ...,\n",
              "           [0.3922, 0.3843, 0.3686,  ..., 0.4078, 0.4039, 0.3804],\n",
              "           [0.3882, 0.3765, 0.3569,  ..., 0.4275, 0.4275, 0.4039],\n",
              "           [0.3804, 0.3686, 0.3529,  ..., 0.4275, 0.4196, 0.3882]],\n",
              " \n",
              "          [[0.7569, 0.7569, 0.7608,  ..., 0.7529, 0.7412, 0.7137],\n",
              "           [0.7569, 0.7569, 0.7647,  ..., 0.7373, 0.7294, 0.7098],\n",
              "           [0.7608, 0.7608, 0.7608,  ..., 0.7216, 0.7176, 0.7059],\n",
              "           ...,\n",
              "           [0.1020, 0.0941, 0.0784,  ..., 0.1412, 0.1373, 0.1137],\n",
              "           [0.0980, 0.0863, 0.0667,  ..., 0.1608, 0.1608, 0.1373],\n",
              "           [0.0902, 0.0784, 0.0627,  ..., 0.1608, 0.1529, 0.1216]]],\n",
              " \n",
              " \n",
              "         [[[0.2353, 0.2353, 0.2353,  ..., 0.2510, 0.2471, 0.2431],\n",
              "           [0.2314, 0.2314, 0.2314,  ..., 0.2510, 0.2471, 0.2431],\n",
              "           [0.2314, 0.2314, 0.2314,  ..., 0.2510, 0.2471, 0.2431],\n",
              "           ...,\n",
              "           [0.5059, 0.5098, 0.5137,  ..., 0.6039, 0.6000, 0.6039],\n",
              "           [0.5098, 0.5098, 0.5098,  ..., 0.6039, 0.6078, 0.6118],\n",
              "           [0.5098, 0.5098, 0.5098,  ..., 0.6078, 0.6157, 0.6235]],\n",
              " \n",
              "          [[0.2902, 0.2902, 0.2902,  ..., 0.3098, 0.3059, 0.3020],\n",
              "           [0.2863, 0.2863, 0.2863,  ..., 0.3098, 0.3059, 0.3020],\n",
              "           [0.2863, 0.2863, 0.2863,  ..., 0.3098, 0.3059, 0.3020],\n",
              "           ...,\n",
              "           [0.3137, 0.3176, 0.3216,  ..., 0.3961, 0.3922, 0.3961],\n",
              "           [0.3176, 0.3176, 0.3176,  ..., 0.3961, 0.4000, 0.4039],\n",
              "           [0.3176, 0.3176, 0.3176,  ..., 0.4000, 0.4078, 0.4157]],\n",
              " \n",
              "          [[0.4039, 0.4039, 0.3961,  ..., 0.4000, 0.3961, 0.3922],\n",
              "           [0.4000, 0.4000, 0.3922,  ..., 0.4000, 0.3961, 0.3922],\n",
              "           [0.3922, 0.3922, 0.3922,  ..., 0.4000, 0.3961, 0.3922],\n",
              "           ...,\n",
              "           [0.0510, 0.0549, 0.0588,  ..., 0.1216, 0.1176, 0.1216],\n",
              "           [0.0549, 0.0549, 0.0549,  ..., 0.1294, 0.1333, 0.1373],\n",
              "           [0.0549, 0.0549, 0.0549,  ..., 0.1333, 0.1412, 0.1490]]],\n",
              " \n",
              " \n",
              "         [[[0.2824, 0.2627, 0.2471,  ..., 0.2118, 0.1569, 0.1647],\n",
              "           [0.2157, 0.2118, 0.2235,  ..., 0.2078, 0.1804, 0.2157],\n",
              "           [0.2039, 0.2039, 0.2118,  ..., 0.2000, 0.2039, 0.2706],\n",
              "           ...,\n",
              "           [0.3412, 0.3725, 0.4039,  ..., 0.3373, 0.3451, 0.3529],\n",
              "           [0.3843, 0.3882, 0.3961,  ..., 0.3412, 0.3412, 0.3451],\n",
              "           [0.3961, 0.3686, 0.3451,  ..., 0.3373, 0.3294, 0.3255]],\n",
              " \n",
              "          [[0.2824, 0.2627, 0.2471,  ..., 0.2157, 0.1608, 0.1686],\n",
              "           [0.2157, 0.2118, 0.2235,  ..., 0.2118, 0.1843, 0.2196],\n",
              "           [0.2039, 0.2039, 0.2118,  ..., 0.2039, 0.2078, 0.2745],\n",
              "           ...,\n",
              "           [0.1686, 0.2000, 0.2314,  ..., 0.1686, 0.1765, 0.1843],\n",
              "           [0.2118, 0.2157, 0.2235,  ..., 0.1725, 0.1725, 0.1765],\n",
              "           [0.2235, 0.1961, 0.1725,  ..., 0.1686, 0.1608, 0.1569]],\n",
              " \n",
              "          [[0.2824, 0.2627, 0.2471,  ..., 0.2235, 0.1686, 0.1765],\n",
              "           [0.2157, 0.2118, 0.2235,  ..., 0.2196, 0.1922, 0.2275],\n",
              "           [0.2039, 0.2039, 0.2118,  ..., 0.2118, 0.2157, 0.2824],\n",
              "           ...,\n",
              "           [0.0000, 0.0157, 0.0471,  ..., 0.0000, 0.0078, 0.0157],\n",
              "           [0.0353, 0.0392, 0.0471,  ..., 0.0000, 0.0000, 0.0000],\n",
              "           [0.0471, 0.0196, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]),\n",
              " 'depth': tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "          ...,\n",
              "          [0.6262, 0.6261, 0.6260,  ..., 0.6303, 0.6302, 0.6302],\n",
              "          [0.6197, 0.6195, 0.6194,  ..., 0.6240, 0.6240, 0.6239],\n",
              "          [0.6131, 0.6130, 0.6129,  ..., 0.6178, 0.6177, 0.6176]],\n",
              " \n",
              "         [[1.0000, 1.0000, 1.0000,  ..., 0.9460, 0.9450, 0.9441],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 0.9458, 0.9449, 0.9445],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 0.9461, 0.9456, 0.9452],\n",
              "          ...,\n",
              "          [0.5822, 0.5822, 0.5822,  ..., 0.5807, 0.5807, 0.5807],\n",
              "          [0.5747, 0.5747, 0.5747,  ..., 0.5731, 0.5731, 0.5731],\n",
              "          [0.5671, 0.5671, 0.5671,  ..., 0.5656, 0.5656, 0.5656]],\n",
              " \n",
              "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "          ...,\n",
              "          [0.5941, 0.5941, 0.5941,  ..., 0.6157, 0.6157, 0.6157],\n",
              "          [0.5871, 0.5871, 0.5871,  ..., 0.6091, 0.6091, 0.6091],\n",
              "          [0.5801, 0.5801, 0.5801,  ..., 0.6025, 0.6025, 0.6025]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[1.0000, 1.0000, 1.0000,  ..., 0.9523, 0.9514, 0.9505],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 0.9524, 0.9514, 0.9505],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 0.9524, 0.9515, 0.9506],\n",
              "          ...,\n",
              "          [0.6107, 0.6107, 0.6108,  ..., 0.6173, 0.6174, 0.6174],\n",
              "          [0.6041, 0.6041, 0.6042,  ..., 0.6107, 0.6108, 0.6108],\n",
              "          [0.5975, 0.5975, 0.5976,  ..., 0.6041, 0.6042, 0.6042]],\n",
              " \n",
              "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "          ...,\n",
              "          [0.6186, 0.6186, 0.6186,  ..., 0.6167, 0.6167, 0.6166],\n",
              "          [0.6120, 0.6120, 0.6120,  ..., 0.6101, 0.6101, 0.6101],\n",
              "          [0.6054, 0.6054, 0.6054,  ..., 0.6035, 0.6035, 0.6035]],\n",
              " \n",
              "         [[0.9264, 0.9271, 0.9278,  ..., 0.9318, 0.9310, 0.9295],\n",
              "          [0.9272, 0.9279, 0.9286,  ..., 0.9324, 0.9316, 0.9304],\n",
              "          [0.9279, 0.9286, 0.9293,  ..., 0.9329, 0.9321, 0.9312],\n",
              "          ...,\n",
              "          [0.5970, 0.5969, 0.5968,  ..., 0.5874, 0.5873, 0.5872],\n",
              "          [0.5900, 0.5899, 0.5898,  ..., 0.5804, 0.5803, 0.5802],\n",
              "          [0.5829, 0.5828, 0.5828,  ..., 0.5733, 0.5733, 0.5732]]]),\n",
              " 'track': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              " \n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              " \n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              " \n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]],\n",
              " \n",
              "         [[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]]])}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P55UWDOSaV1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmZKJ4z9SMEN"
      },
      "outputs": [],
      "source": [
        "class ClassificationLoss_detection(nn.Module):\n",
        "    def forward(self, logits: torch.Tensor, target: torch.LongTensor, weight: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Multi-class classification loss\n",
        "        Hint: simple one-liner\n",
        "\n",
        "        Args:\n",
        "            logits: tensor (b, c) logits, where c is the number of classes\n",
        "            target: tensor (b,) labels\n",
        "\n",
        "        Returns:\n",
        "            tensor, scalar loss\n",
        "        \"\"\"\n",
        "        #raise NotImplementedError(\"ClassificationLoss.forward() is not implemented\")\n",
        "        return nn.functional.cross_entropy(logits, target, weight=weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtdsL9r0SdLq"
      },
      "outputs": [],
      "source": [
        "class_wgt = [0.33,0.33,0.33]\n",
        "class_weights = torch.tensor(class_wgt, dtype=torch.float)\n",
        "class_loss_func = ClassificationLoss_detection()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNVVGw16uQVwX5F4/BDJ/Sv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}